# -*- coding: utf-8 -*-
"""Smart_grid.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qltvZPa0wFoXRoFnZHqXdcI4JnY_ZFUA
"""

import pandas as pd

def load_data(filepath='/content/smart_grid_dataset.csv'):

    try:
        df = pd.read_csv(filepath)
        print(f"Data loaded successfully. Shape: {df.shape}")
        return df
    except FileNotFoundError:
        print(f"File not found at path: {filepath}")
        return pd.DataFrame()
    except Exception as e:
        print(f"Error loading data: {e}")
        return pd.DataFrame()

# Call the load_data function and assign its result to df
df = load_data()

# Step 2: Preprocessing

import numpy as np
from sklearn.preprocessing import StandardScaler # Ensure StandardScaler is imported

# Define the correct target column name based on initial check
target_column_original_name = 'Power Consumption (kW)' # <-- Update this if the name is different based on your dataset

# 1. Check for missing values
missing_values = df.isnull().sum()
print("Missing values per column:\n", missing_values)

# 2. Handle missing values (forward fill, then backward fill as backup)
df = df.ffill().bfill()

# 3. Ensure datetime index is sorted
# Check if 'Timestamp' column exists before setting it as index
if 'Timestamp' in df.columns:
    # Convert 'Timestamp' to datetime objects and set as index
    df['Timestamp'] = pd.to_datetime(df['Timestamp'])
    df = df.set_index('Timestamp')
else:
    print("Warning: 'Timestamp' column not found. Assuming index is already datetime or not needed for indexing.")
    # If 'Timestamp' is not present, assume the index is already the datetime index
    # or handle based on your dataset structure. If the index is not datetime and there's
    # no timestamp column, scaling numerical features might still work, but time-based
    # features later will fail. For this dataset, 'Timestamp' is expected.
    # If the index needs conversion, add it here:
    # df.index = pd.to_datetime(df.index)


df = df.sort_index()

# 4. Check for duplicate timestamps (now checking on the index)
duplicates = df.index.duplicated().sum()
print(f"Number of duplicated timestamps: {duplicates}")
df = df[~df.index.duplicated(keep='first')]

# 5. Check data types
print("Data types:\n", df.dtypes)

# 6. Optional: Convert categorical columns to category dtype if any
# After setting 'Timestamp' as index, this loop should not find 'Timestamp'
categorical_cols = df.select_dtypes(include='object').columns
for col in categorical_cols:
    df[col] = df[col].astype('category')
    print(f"Converted column '{col}' to category.")


# --- Start Changes ---
# 7. Normalize numerical features (excluding target and index)

# Separate features and target BEFORE scaling
# Check if the target column exists before attempting to separate
if target_column_original_name in df.columns:
    target = df[target_column_original_name]
    features = df.drop(columns=target_column_original_name) # Drop the target column from features
else:
    # Handle the case where the target column is not found (shouldn't happen if Step 1 is correct)
    print(f"Error: Target column '{target_column_original_name}' not found in the DataFrame.")
    # Decide how to proceed - maybe raise an error or stop execution
    # For now, we'll raise an error to prevent further issues
    raise KeyError(f"Target column '{target_column_original_name}' not found.")


# Ensure that the 'features' DataFrame now only contains numerical columns or columns StandardScaler can handle.
# Check data types of features before scaling
print("Features data types before scaling:\n", features.dtypes)

# Select only numerical columns for scaling if there might be other non-numerical columns left
numerical_features = features.select_dtypes(include=np.number)

if numerical_features.empty:
    print("Warning: No numerical features found to scale.")
    # Handle this case appropriately, maybe skip scaling or raise an error
    scaled_features = numerical_features.copy() # Create an empty DataFrame or handle as needed
else:
    scaler = StandardScaler()
    scaled_features = scaler.fit_transform(numerical_features)
    # Convert scaled array back to DataFrame with correct columns and index
    scaled_features = pd.DataFrame(scaled_features, index=numerical_features.index, columns=numerical_features.columns)

    # If there were non-numerical features (e.g., categorical converted from object),
    # you might need to re-join them with the scaled numerical features here.
    # For this specific error cause (Timestamp), setting index resolves it.
    # If other non-numerical columns exist and shouldn't be scaled, handle them:
    # non_numerical_features = features.select_dtypes(exclude=np.number)
    # df_scaled = pd.concat([scaled_features, non_numerical_features], axis=1)


# Reconstruct the DataFrame with scaled features and the original target
# If numerical_features was not empty, scaled_features is a DataFrame
# If numerical_features was empty, scaled_features is also an empty DataFrame
df_scaled = scaled_features

# Re-attach target column using the correct name
df_scaled[target_column_original_name] = target # Attach the original target series

# Optionally rename the target column to 'load' for consistency in later steps if preferred
# Make sure to update all subsequent code that refers to 'load' if you don't rename here.
# Let's rename it here to 'load' as the later code expects 'load'
df_scaled = df_scaled.rename(columns={target_column_original_name: 'load'})

print(f"Target column '{target_column_original_name}' renamed to 'load' in df_scaled.")
# --- End Changes ---


# Final preview
print("Preprocessed dataset preview:\n", df_scaled.head())

# Verify 'load' column exists in df_scaled
print("Columns in df_scaled after preprocessing:", df_scaled.columns.tolist())

# Step 3: Exploratory Data Analysis (EDA)

import matplotlib.pyplot as plt
import seaborn as sns

# Set visualization style
sns.set(style='whitegrid')

# --- Diagnosis Step: Check columns before plotting ---
print("Columns in df_scaled:", df_scaled.columns.tolist())
# -----------------------------------------------------

# 1. Basic statistics
print("Statistical summary:\n", df_scaled.describe())

# 2. Time series plot of the target variable ('load')
plt.figure(figsize=(14, 5))
# If the column name is different, replace 'load' with the correct name
plt.plot(df_scaled.index, df_scaled['load'], label='Load')
plt.title("Time Series of Electrical Load")
plt.xlabel("Timestamp")
plt.ylabel("Load")
plt.legend()
plt.tight_layout()
plt.show()

# 3. Histogram of the target variable
plt.figure(figsize=(8, 5))
# If the column name is different, replace 'load' with the correct name
sns.histplot(df_scaled['load'], bins=50, kde=True)
plt.title("Distribution of Load")
plt.xlabel("Load")
plt.ylabel("Frequency")
plt.tight_layout()
plt.show()

# 4. Heatmap of correlations
plt.figure(figsize=(10, 8))
corr = df_scaled.corr()
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title("Correlation Heatmap")
plt.tight_layout()
plt.show()

# 5. Seasonal/Hourly patterns (if time features are available)
if 'hour' not in df_scaled.columns:
    df_scaled['hour'] = df_scaled.index.hour
if 'dayofweek' not in df_scaled.columns:
    df_scaled['dayofweek'] = df_scaled.index.dayofweek

# Boxplot by hour
plt.figure(figsize=(12, 5))
# If the column name is different, replace 'load' with the correct name
sns.boxplot(x='hour', y='load', data=df_scaled)
plt.title("Load by Hour of Day")
plt.xlabel("Hour")
plt.ylabel("Load")
plt.tight_layout()
plt.show()

# Boxplot by day of week
plt.figure(figsize=(12, 5))
# If the column name is different, replace 'load' with the correct name
sns.boxplot(x='dayofweek', y='load', data=df_scaled)
plt.title("Load by Day of Week")
plt.xlabel("Day of Week (0=Monday)")
plt.ylabel("Load")
plt.tight_layout()
plt.show()

# Step 4: Feature Engineering

# We assume df_scaled already contains the cleaned and preprocessed data
# with datetime index and a detected target column (e.g., 'load')

# Identify target column
target_column = next((col for col in df_scaled.columns if 'load' in col.lower()), None)

# 1. Create lag features (previous load values)
for lag in range(1, 25):  # past 24 hours
    df_scaled[f'{target_column}_lag_{lag}'] = df_scaled[target_column].shift(lag)

# 2. Create rolling statistics
df_scaled[f'{target_column}_rolling_mean_24h'] = df_scaled[target_column].rolling(window=24).mean()
df_scaled[f'{target_column}_rolling_std_24h'] = df_scaled[target_column].rolling(window=24).std()

# 3. Time-based features (already added in EDA, but re-ensuring here)
df_scaled['hour'] = df_scaled.index.hour
df_scaled['dayofweek'] = df_scaled.index.dayofweek
df_scaled['month'] = df_scaled.index.month

# 4. Drop rows with NaN values introduced by lag/rolling
df_features = df_scaled.dropna()

# 5. Finalize features and target
X = df_features.drop(columns=[target_column])
y = df_features[target_column]

# 6. Split into train/test sets (time-based split)
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, shuffle=False
)

# Show final shape
print("Training features shape:", X_train.shape)
print("Testing features shape:", X_test.shape)
print("Target variable:", target_column)

# Step 5: Modeling

from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from keras.models import Sequential
from keras.layers import Dense, LSTM
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np # Ensure numpy is imported for reshape and flatten

# Add a check to ensure training data is defined
if 'X_train' not in globals() or 'y_train' not in globals():
    print("Error: Training data (X_train, y_train) is not loaded. Please run the 'Step 4: Feature Engineering' cell first.")
else:
    # Proceed with modeling only if X_train and y_train are defined

    # -------------------------------
    # Model 1: Linear Regression
    # -------------------------------
    lr_model = LinearRegression()
    lr_model.fit(X_train, y_train)
    lr_pred = lr_model.predict(X_test)

    # -------------------------------
    # Model 2: Random Forest
    # -------------------------------
    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
    rf_model.fit(X_train, y_train)
    rf_pred = rf_model.predict(X_test)

    # -------------------------------
    # Model 3: LSTM Neural Network
    # -------------------------------

    # Reshape input to [samples, time steps, features]
    X_train_lstm = np.reshape(X_train.values, (X_train.shape[0], 1, X_train.shape[1]))
    X_test_lstm = np.reshape(X_test.values, (X_test.shape[0], 1, X_test.shape[1]))

    lstm_model = Sequential()
    lstm_model.add(LSTM(50, activation='relu', input_shape=(1, X_train.shape[1])))
    lstm_model.add(Dense(1))
    lstm_model.compile(optimizer='adam', loss='mse')
    # Use verbose=0 to avoid printing training progress if desired
    lstm_model.fit(X_train_lstm, y_train, epochs=10, verbose=0)

    lstm_pred = lstm_model.predict(X_test_lstm).flatten()

    # Store predictions for evaluation
    predictions = {
        "Linear Regression": lr_pred,
        "Random Forest": rf_pred,
        "LSTM": lstm_pred
    }
    print("Modeling step completed.")

# ---- Baseline Median Model ----
import pandas as pd # Ensure pandas is imported for Series operations
import matplotlib.pyplot as plt # Ensure matplotlib is imported for plotting
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score # Ensure metrics are imported

# Define the evaluation function here
def evaluate_model(y_true, y_pred, model_name="Model"):
    # Ensure y_true and y_pred are aligned before calculating metrics
    # Assuming they are pandas Series with a common index after train_model modification
    y_true_aligned, y_pred_aligned = y_true.align(y_pred, join='inner')


    mae = mean_absolute_error(y_true_aligned, y_pred_aligned)
    mse = mean_squared_error(y_true_aligned, y_pred_aligned)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_true_aligned, y_pred_aligned)

    print(f"\n{model_name} Evaluation Metrics:")
    print(f"MAE  : {mae:.4f}")
    print(f"MSE  : {mse:.4f}")
    print(f"RMSE : {rmse:.4f}")
    print(f"R2   : {r2:.4f}")

    # Plot true vs predicted values using their index
    plt.figure(figsize=(12, 5))
    # Plotting directly from pandas Series with datetime index
    plt.plot(y_true_aligned.index, y_true_aligned.values, label='True', linewidth=2)
    plt.plot(y_pred_aligned.index, y_pred_aligned.values, label='Predicted', linewidth=2)
    plt.title(f"{model_name} - True vs Predicted Load")
    plt.xlabel("Timestamp") # Updated xlabel to reflect DatetimeIndex
    plt.ylabel("Power Consumption (kW)")
    plt.legend()
    plt.tight_layout()
    plt.show()

    return {"MAE": mae, "MSE": mse, "RMSE": rmse, "R2": r2}


def baseline_median_model(X_test, y_train):
    median_value = y_train.median()
    y_pred_baseline_median = np.full(shape=len(X_test), fill_value=median_value)
    # Return as a pandas Series with the same index as X_test for consistency with evaluate_model
    return pd.Series(y_pred_baseline_median, index=X_test.index)


# Use correct y_train (i.e., corresponding to training portion of 'load')
# Pass X_test to baseline_median_model so the returned Series has the correct index
y_pred_baseline_median = baseline_median_model(X_test, y_train)

# Evaluate using existing evaluation function
evaluate_model(y_test, y_pred_baseline_median, "Baseline Median Model")

# ---- Confidence Intervals for Random Forest ----
def rf_confidence_intervals(model, X_test, confidence=0.95):
    # Ensure X_test is a pandas DataFrame
    if not isinstance(X_test, pd.DataFrame):
        # Convert if necessary, although it should be a DataFrame from train_test_split
        X_test = pd.DataFrame(X_test)
    all_preds = np.stack([tree.predict(X_test.values) for tree in model.estimators_])
    lower_bound = np.percentile(all_preds, ((1 - confidence) / 2) * 100, axis=0)
    upper_bound = np.percentile(all_preds, (1 - (1 - confidence) / 2) * 100, axis=0)
    mean_preds = np.mean(all_preds, axis=0)
    return mean_preds, lower_bound, upper_bound
y_pred_rf, lower, upper = rf_confidence_intervals(rf_model, X_test)
# -----------------------------------------------------------------------------

# Plot with confidence intervals
import matplotlib.pyplot as plt
import pandas as pd # Ensure pandas is imported here

plt.figure(figsize=(12, 6))
# Plotting against the index of X_test or y_test to align with time
plt.plot(y_test.index, y_test.values, label='Actual', color='black')
# Ensure y_pred_rf has the correct index by using X_test.index
y_pred_rf_series = pd.Series(y_pred_rf, index=X_test.index)
lower_series = pd.Series(lower, index=X_test.index)
upper_series = pd.Series(upper, index=X_test.index)

# Use the index from X_test for fill_between as well
plt.plot(y_pred_rf_series.index, y_pred_rf_series.values, label='RF Predicted', color='blue')
plt.fill_between(X_test.index, lower_series, upper_series, color='blue', alpha=0.3, label='95% CI')
plt.title("Random Forest Predictions with 95% Confidence Interval")
plt.xlabel("Timestamp") # Use Timestamp as xlabel since index is datetime
plt.ylabel("Power Consumption (kW)")
plt.legend()
plt.tight_layout()
plt.show()

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import pandas as pd # Ensure pandas is imported for pd.Series and pd.concat
import matplotlib.pyplot as plt # Ensure matplotlib is imported for plotting
from IPython.display import display # Import display for showing dataframes in notebook

# The target_column variable was determined in the Feature Engineering step
# Make sure it's accessible or pass it to the function

def train_model(data_features, target_col_name, n_splits=5):
    # Define the features used for training
    # Use the actual column names created in feature engineering
    features_to_use = ["hour", "dayofweek", f"{target_col_name}_rolling_mean_24h"]

    # Check if features exist before selecting
    missing_features = [f for f in features_to_use if f not in data_features.columns]
    if missing_features:
        print(f"Error: Missing features in the DataFrame: {missing_features}")
        print("Available columns:", data_features.columns.tolist())
        raise KeyError(f"Missing features for training: {missing_features}")


    X = data_features[features_to_use].values
    y = data_features[target_col_name].values # Use the determined target column name

    tscv = TimeSeriesSplit(n_splits=n_splits)

    fold_scores = []
    all_y_true = pd.Series(dtype=y.dtype) # Initialize as Series for concatenation
    all_y_pred = pd.Series(dtype=y.dtype) # Initialize as Series for concatenation

    # Store predictions with their original indices for plotting
    all_predictions = pd.Series(dtype=y.dtype)
    all_actuals = pd.Series(dtype=y.dtype)


    model = None # Initialize model outside the loop

    for fold, (train_idx, test_idx) in enumerate(tscv.split(X)):
        X_train, X_test = X[train_idx], X[test_idx]
        y_train, y_test = y[train_idx], y[test_idx]

        # Get the actual indices for the test set
        test_indices = data_features.index[test_idx]


        model = RandomForestRegressor(n_estimators=100, random_state=42)
        model.fit(X_train, y_train)

        y_pred = model.predict(X_test)

        # Append predictions and actuals with their indices
        fold_predictions = pd.Series(y_pred, index=test_indices)
        fold_actuals = pd.Series(y_test, index=test_indices)

        all_predictions = pd.concat([all_predictions, fold_predictions])
        all_actuals = pd.concat([all_actuals, fold_actuals])

        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        fold_scores.append(rmse)

    # Ensure predictions and actuals are sorted by index for plotting
    all_predictions = all_predictions.sort_index()
    all_actuals = all_actuals.sort_index()
    avg_rmse = np.mean(fold_scores)

    # Return the sorted predictions, actuals, scores, and the list of features used
    return model, all_actuals, all_predictions, avg_rmse, fold_scores, features_to_use

show_forecast = True

if show_forecast:
    # st.subheader("ðŸ”® Forecasting with Random Forest + CV") # Replace with print
    print("\nðŸ”® Forecasting with Random Forest + CV")
    if 'target_column' not in globals():
         print("Error: target_column not defined. Please run the Feature Engineering cell first.")
    else:
        model, y_true, y_pred, avg_rmse, fold_scores, features = train_model(df_features, target_column)

        forecast_df = pd.DataFrame({
            "Actual": y_true,
            "Predicted": y_pred
        })

        # st.line_chart(forecast_df) # Replace with matplotlib plot or display
        print("\nForecast Plot (Actual vs Predicted):")
        plt.figure(figsize=(14, 6))
        plt.plot(forecast_df.index, forecast_df['Actual'], label='Actual')
        plt.plot(forecast_df.index, forecast_df['Predicted'], label='Predicted')
        plt.title("Random Forest + CV Forecast: Actual vs Predicted")
        plt.xlabel("Timestamp")
        plt.ylabel(target_column)
        plt.legend()
        plt.tight_layout()
        plt.show()

        # st.metric("Average CV RMSE", f"{avg_rmse:.2f}") # Replace with print
        print(f"Average CV RMSE: {avg_rmse:.2f}")

        # ðŸ“Œ Feature Importance Plot
        # st.subheader("ðŸ“Œ Feature Importance (Random Forest)") # Replace with print
        print("\nðŸ“Œ Feature Importance (Random Forest)")

        # The 'model' variable is returned by train_model
        if model is not None:
            importances = model.feature_importances_
            importance_df = pd.DataFrame({
                "Feature": features, # 'features' is now returned by train_model
                "Importance": importances
            }).sort_values(by="Importance", ascending=False)

            fig, ax = plt.subplots(figsize=(10, 6)) # Adjust figure size
            ax.barh(importance_df["Feature"], importance_df["Importance"], color="skyblue")
            ax.set_xlabel("Importance")
            ax.set_title("Random Forest Feature Importance")
            plt.gca().invert_yaxis() # Invert axis to show highest importance at the top
            plt.tight_layout()
            # st.pyplot(fig) # Replace with plt.show()
            plt.show()
        else:
             print("Model could not be trained.")

# Evaluation
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

def evaluate_model(y_true, y_pred, model_name="Model"):
    # Ensure y_true and y_pred are aligned before calculating metrics
    # Assuming they are pandas Series with a common index after train_model modification
    y_true_aligned, y_pred_aligned = y_true.align(y_pred, join='inner')


    mae = mean_absolute_error(y_true_aligned, y_pred_aligned)
    mse = mean_squared_error(y_true_aligned, y_pred_aligned)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_true_aligned, y_pred_aligned)

    print(f"\n{model_name} Evaluation Metrics:")
    print(f"MAE  : {mae:.4f}")
    print(f"MSE  : {mse:.4f}")
    print(f"RMSE : {rmse:.4f}")
    print(f"R2   : {r2:.4f}")

    # Plot true vs predicted values using their index
    plt.figure(figsize=(12, 5))
    # Plotting directly from pandas Series with datetime index
    plt.plot(y_true_aligned.index, y_true_aligned.values, label='True', linewidth=2)
    plt.plot(y_pred_aligned.index, y_pred_aligned.values, label='Predicted', linewidth=2)
    plt.title(f"{model_name} - True vs Predicted Load")
    plt.xlabel("Timestamp") # Updated xlabel to reflect DatetimeIndex
    plt.ylabel("Power Consumption (kW)")
    plt.legend()
    plt.tight_layout()
    plt.show()

    return {"MAE": mae, "MSE": mse, "RMSE": rmse, "R2": r2}

# Train and evaluate
model, y_true, y_pred, avg_rmse, fold_scores, features = train_model(df_features, target_column)

# Evaluate
metrics = evaluate_model(y_true, y_pred, model_name="Random Forest with CV")

print(f"\nCross-Validation RMSEs per Fold: {fold_scores}")
print(f"Average CV RMSE: {avg_rmse:.4f}")

# Replace Streamlit commands with print for notebook output
print("\nðŸ“ˆ Cross-Validation Results")
print(f"Avg CV RMSE: {avg_rmse:.2f}")
print("Fold RMSEs:", {f"Fold {i+1}": f"{rmse:.2f}" for i, rmse in enumerate(fold_scores)})

print("\nðŸ“Š Model Performance")
# For model performance visualization, the evaluate_model function already plots the true vs predicted line chart.
# If you need to display the dataframe itself, you can print or display it:
display(pd.DataFrame({"Actual": y_true, "Predicted": y_pred}))

# Step 7: Interpretation using SHAP
import shap
from sklearn.ensemble import RandomForestRegressor # Ensure this is imported if needed

# Use a simpler model for SHAP (Random Forest in this case)
# Disable the additivity check if minor floating point differences are acceptable

# Ensure rf_model, X_train, and X_test are defined from the Modeling step
# If running cells out of order, you might need to rerun the Modeling cell first.
if 'rf_model' not in globals() or 'X_train' not in globals() or 'X_test' not in globals():
    print("Error: rf_model, X_train, and X_test are not defined. Please run the 'Step 5: Modeling' cell first.")
else:
    # Pass check_additivity=False to the explainer call
    explainer = shap.Explainer(rf_model, X_train)
    shap_values = explainer(X_test, check_additivity=False) # Disable additivity check

# ---------------------------
# 1. SHAP Summary Plot
# ---------------------------
shap.plots.beeswarm(shap_values, max_display=15)

# ---------------------------
# 2. SHAP Bar Plot (Mean absolute SHAP value)
# ---------------------------
shap.plots.bar(shap_values, max_display=15)

# ---------------------------
# 3. SHAP Dependence Plots for Top Features
# ---------------------------
# Get top 3 features based on mean(|SHAP|)
top_features = np.argsort(np.abs(shap_values.values).mean(0))[-3:]
top_feature_names = [X_train.columns[i] for i in top_features]

for feature in top_feature_names:
    shap.plots.scatter(shap_values[:, feature], color=shap_values)

# ---------------------------
# 4. SHAP Force Plot for a Single Prediction
# ---------------------------
# Use one sample from the test set
sample_index = 0
sample = X_test.iloc[[sample_index]]
sample_shap_values = explainer(sample)

# Force plot visualization (JS-based, for use in notebooks)
shap.initjs()
shap.force_plot(explainer.expected_value, sample_shap_values.values, sample, matplotlib=True)

# %%
# ðŸ’¾ Save model, scaler, and SHAP explainer
import pickle
import joblib # Using joblib for the model as it's often preferred for scikit-learn models

# Save the Random Forest model
joblib.dump(rf_model, 'rf_model.joblib')
print("rf_model saved to rf_model.joblib")

# Save the StandardScaler
with open("scaler.pkl", "wb") as f:
    pickle.dump(scaler, f)
print("scaler saved to scaler.pkl")

# Save the SHAP explainer
# Note: Saving SHAP explainers with pickle/joblib can sometimes be tricky,
# especially with complex models or large datasets. This approach works for TreeExplainers.
with open("explainer.pkl", "wb") as f:
    pickle.dump(explainer, f)
print("explainer saved to explainer.pkl")

# You might also want to save the other models if needed later
# with open("lr_model.pkl", "wb") as f:
#     pickle.dump(lr_model, f)
# with open("lstm_model.pkl", "wb") as f:
#     pickle.dump(lstm_model, f)

# Save the StandardScaler
with open("model.pkl", "wb") as f:
    pickle.dump(model, f)
print("scaler saved to model.pkl")

